{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GC-SEG Pipeline Notebook\n",
    "\n",
    "This notebook demonstrates the complete GeometryCrafter Segmented (GC-SEG) pipeline for processing long videos.\n",
    "\n",
    "## Pipeline Phases\n",
    "\n",
    "1. **Phase 1**: Video metadata probing and segment mapping\n",
    "2. **Phase 2**: Run AI inference on each segment\n",
    "3. **Phase 3**: Extract disparity PNGs from NPZ segments\n",
    "4. **Phase 4**: Compute scale/shift alignment between segments\n",
    "5. **Phase 5**: Merge aligned frames with seamless blending\n",
    "6. **Phase 6**: Apply bilateral filter and encode to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI2\\GeometryCrafter\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from gc_seg import (\n",
    "    create_segment_mapping,\n",
    "    process_video_segments,\n",
    "    extract_disparity_frames,\n",
    "    compute_alignment,\n",
    "    merge_segments,\n",
    "    process_video,\n",
    "    Encoder,\n",
    ")\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up your video path and parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resolution: 512x320\n",
      "Video: workspace/input/AWO_clip2_V1-1520.mp4\n",
      "Window: 80, Overlap: 20\n",
      "Output: workspace\\output.mp4\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "VIDEO_PATH = \"workspace/input/AWO_clip2_V1-1520.mp4\"  # Path to input video\n",
    "\n",
    "# Segment parameters\n",
    "WINDOW_SIZE = 80  # Frames per segment\n",
    "OVERLAP = 20  # Overlap between segments\n",
    "\n",
    "# Processing parameters\n",
    "HEIGHT = 320  # Output height (must be divisible by 64)\n",
    "WIDTH = 512  # Output width (must be divisible by 64)\n",
    "\n",
    "# Round up to nearest multiple of 64 if needed\n",
    "HEIGHT = ((HEIGHT + 63) // 64) * 64\n",
    "WIDTH = ((WIDTH + 63) // 64) * 64\n",
    "print(f\"Processing resolution: {WIDTH}x{HEIGHT}\")\n",
    "\n",
    "MODEL_TYPE = \"diff\"  # 'diff' or 'determ'\n",
    "NUM_INFERENCE_STEPS = 5\n",
    "LOW_MEMORY_USAGE = True\n",
    "DECODE_CHUNK_SIZE = 6\n",
    "# Calculate downsample ratio to process at target resolution\n",
    "# Example: if video is 1920x1080 and you want 320x512:\n",
    "# downsample_ratio = 1080 / 320 = 3.375\n",
    "DOWNSAMPLE_RATIO = 1.0\n",
    "\n",
    "# Output folders\n",
    "WORKSPACE = Path(\"workspace\")\n",
    "SEGMENTS_FOLDER = WORKSPACE / \"segments\"\n",
    "TEMP_FRAMES_FOLDER = WORKSPACE / \"temp_frames\"\n",
    "MERGED_FRAMES_FOLDER = WORKSPACE / \"merged_frames\"\n",
    "OUTPUT_PATH = WORKSPACE / \"output.mp4\"\n",
    "\n",
    "\n",
    "# Alignment JSON path\n",
    "ALIGNMENT_PATH = WORKSPACE / \"alignment.json\"\n",
    "\n",
    "# Create workspace folder\n",
    "WORKSPACE.mkdir(exist_ok=True)\n",
    "\n",
    "# Phase 5: Merge options\n",
    "BYPASS_ALIGNMENT = True  # Set True to skip scale/shift alignment\n",
    "# if BYPASS_ALIGNMENT and not ALIGNMENT_PATH.exists():\n",
    "#      ALIGNMENT_PATH.write_text('{\"overlap\": 25, \"alignments\": []}')\n",
    "    \n",
    "CLEAN_MERGED_OUTPUT = True  # Clean merged folder before processing\n",
    "\n",
    "# Phase 6: Video encoding options\n",
    "ENCODER = \"x265\"  # Options: \"x265\", \"h264\", \"nvenc_h264\", \"nvenc_hevc\"\n",
    "# For NVENC: use preset \"p1\" (fastest) to \"p7\" (best quality), e.g., \"p4\"\n",
    "# For CPU: use preset \"ultrafast\" to \"veryslow\", e.g., \"medium\"\n",
    "ENCODER_PRESET = \"medium\"\n",
    "BYPASS_BILATERAL = True\n",
    "UPSCALE_RES = None  # Keep low res: 512x276\n",
    "# UPSCALE_RES = (1912, 1036)  # Upscale to original video resolution\n",
    "\n",
    "print(f\"Video: {VIDEO_PATH}\")\n",
    "print(f\"Window: {WINDOW_SIZE}, Overlap: {OVERLAP}\")\n",
    "print(f\"Output: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Metadata & Segment Mapping\n",
    "\n",
    "Probe video metadata and create segment mapping with specified window size and overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PHASE 1: Metadata & Segment Mapping\n",
      "==================================================\n",
      "\n",
      "Video: 113 frames @ 24.00 FPS\n",
      "Resolution: 1912x1036\n",
      "Created 2 segments:\n",
      "\n",
      "  Segment 0: frames 0-79 (80 frames)\n",
      "  Segment 1: frames 60-112 (53 frames)\n",
      "\n",
      "Mapping saved to: workspace\\segment_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Create segment mapping\n",
    "print(\"=\" * 50)\n",
    "print(\"PHASE 1: Metadata & Segment Mapping\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "mapping = create_segment_mapping(\n",
    "    VIDEO_PATH,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    overlap=OVERLAP,\n",
    ")\n",
    "\n",
    "print(f\"\\nVideo: {mapping.metadata.num_frames} frames @ {mapping.metadata.fps:.2f} FPS\")\n",
    "print(f\"Resolution: {mapping.metadata.width}x{mapping.metadata.height}\")\n",
    "print(f\"Created {len(mapping.segments)} segments:\\n\")\n",
    "\n",
    "for i, seg in enumerate(mapping.segments):\n",
    "    print(f\"  Segment {i}: frames {seg.start_frame}-{seg.end_frame} ({seg.frame_count} frames)\")\n",
    "\n",
    "# Save mapping to JSON\n",
    "mapping_json_path = WORKSPACE / \"segment_mapping.json\"\n",
    "mapping.to_json(mapping_json_path)\n",
    "print(f\"\\nMapping saved to: {mapping_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Run AI Inference on Segments\n",
    "\n",
    "Process each segment through the GeometryCrafter model to generate point maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset segments folder (run this to clear npz files)\n",
    "import shutil\n",
    "if SEGMENTS_FOLDER.exists():\n",
    "    shutil.rmtree(SEGMENTS_FOLDER)\n",
    "SEGMENTS_FOLDER.mkdir(exist_ok=True)\n",
    "print(f\"Reset {SEGMENTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Run AI inference on each segment\n",
    "print(\"=\" * 50)\n",
    "print(\"PHASE 2: AI Inference on Segments\")\n",
    "print(\"=\" * 50)\n",
    "# Check if video has odd dimensions and force resize if needed\n",
    "orig_width = mapping.metadata.width\n",
    "orig_height = mapping.metadata.height\n",
    "print(f\"Original video: {orig_width}x{orig_height}\")\n",
    "if orig_width % 2 != 0 or orig_height % 2 != 0:\n",
    "    print(\"WARNING: Video has odd dimensions, forcing resize...\")\n",
    "    # Calculate downsample ratio to get to target while ensuring even dims\n",
    "    ratio_w = orig_width / WIDTH\n",
    "    ratio_h = orig_height / HEIGHT\n",
    "    DOWNSAMPLE_RATIO = max(ratio_w, ratio_h)\n",
    "    print(f\"Using downsample_ratio: {DOWNSAMPLE_RATIO:.2f}\")\n",
    "else:\n",
    "    DOWNSAMPLE_RATIO = None  # Let it process at original res if even\n",
    "segment_paths = process_video_segments(\n",
    "    video_path=VIDEO_PATH,\n",
    "    segment_mapping=mapping,\n",
    "    save_folder=str(SEGMENTS_FOLDER),\n",
    "    height=HEIGHT,\n",
    "    width=WIDTH,\n",
    "    model_type=MODEL_TYPE,\n",
    "    num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "    low_memory_usage=LOW_MEMORY_USAGE,\n",
    "    decode_chunk_size=DECODE_CHUNK_SIZE,\n",
    "    downsample_ratio=DOWNSAMPLE_RATIO,  # Force resize if odd\n",
    "    keep_low_res=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(segment_paths)} segments:\")\n",
    "for p in segment_paths:\n",
    "    print(f\"  {p.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Extract Disparity PNGs\n",
    "\n",
    "Extract the Z-channel (depth/disparity) from point maps and save as 16-bit PNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset temp frames folder (run this to clear extracted PNGs without deleting NPZ segments)\n",
    "import shutil\n",
    "if TEMP_FRAMES_FOLDER.exists():\n",
    "    shutil.rmtree(TEMP_FRAMES_FOLDER)\n",
    "TEMP_FRAMES_FOLDER.mkdir(exist_ok=True)\n",
    "print(f\"Reset {TEMP_FRAMES_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Extract disparity frames\n",
    "print(\"=\" * 50)\n",
    "print(\"PHASE 3: Extract Disparity PNGs\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "extract_disparity_frames(\n",
    "    segments_folder=str(SEGMENTS_FOLDER),\n",
    "    output_folder=str(TEMP_FRAMES_FOLDER),\n",
    "    invert=True,\n",
    ")\n",
    "\n",
    "# Count extracted frames\n",
    "total_frames = 0\n",
    "for seg_dir in sorted(TEMP_FRAMES_FOLDER.glob(\"part_*\")):\n",
    "    num_frames = len(list(seg_dir.glob(\"*.png\")))\n",
    "    print(f\"  {seg_dir.name}: {num_frames} frames\")\n",
    "    total_frames += num_frames\n",
    "\n",
    "print(f\"\\nTotal extracted: {total_frames} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Compute Alignment\n",
    "\n",
    "Calculate scale (s) and shift (t) coefficients to align overlapping frames between segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4: Compute alignment\n",
    "print(\"=\" * 50)\n",
    "print(\"PHASE 4: Compute Scale/Shift Alignment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if len(mapping.segments) < 2:\n",
    "    print(\"Only one segment - no alignment needed!\")\n",
    "    alignments = []\n",
    "else:\n",
    "    alignments = compute_alignment(\n",
    "        segments_folder=str(TEMP_FRAMES_FOLDER),\n",
    "        segment_mapping=mapping,\n",
    "        output_path=ALIGNMENT_PATH,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nAlignment coefficients saved to: {ALIGNMENT_PATH}\")\n",
    "    print(\"\\nSummary:\")\n",
    "    for a in alignments:\n",
    "        print(f\"  Segment {a.segment_a_index} -> {a.segment_b_index}: s={a.scale:.6f}, t={a.shift:.6f}, RMSE={a.rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Merge & Blend Frames\n",
    "\n",
    "Apply alignment transformations and blend overlapping regions to create seamless output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset merged frames folder (run this to clear extracted PNGs inside the merged frames folder)\n",
    "import shutil\n",
    "if MERGED_FRAMES_FOLDER.exists():\n",
    "    shutil.rmtree(MERGED_FRAMES_FOLDER)\n",
    "MERGED_FRAMES_FOLDER.mkdir(exist_ok=True)\n",
    "print(f\"Reset {MERGED_FRAMES_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 5: Merge and blend frames\n",
    "print(\"=\" * 50)\n",
    "print(\"PHASE 5: Merge & Blend Frames\")\n",
    "print(\"=\" * 50)\n",
    "merged_paths = merge_segments(\n",
    "    segments_folder=str(TEMP_FRAMES_FOLDER),\n",
    "    segment_mapping=mapping,\n",
    "    alignment_path=str(ALIGNMENT_PATH),\n",
    "    output_folder=str(MERGED_FRAMES_FOLDER),\n",
    "    blend_mode=\"sigmoid\",  # or \"linear\"\n",
    "    blend_sigma=6.0,\n",
    "    bypass_alignment=BYPASS_ALIGNMENT,  # Skip scale/shift if True\n",
    "    clean_output=CLEAN_MERGED_OUTPUT,   # Clean old frames before merging\n",
    ")\n",
    "\n",
    "print(f\"\\nMerged {len(merged_paths)} frames to: {MERGED_FRAMES_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Post-Process & Encode\n",
    "\n",
    "Apply joint bilateral filter for edge-preserving smoothing and encode to x265 10-bit video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PHASE 6: Post-Process & Encode\n",
      "==================================================\n",
      "Bypass bilateral: False\n",
      "Applying joint bilateral filter to 113 frames...\n",
      "  Processed 50/113 frames\n",
      "  Processed 100/113 frames\n",
      "Saving filtered frames to workspace\\filtered_frames\n",
      "Upscaling frames to 1912x1036...\n",
      "Upscaled 113 frames\n",
      "Encoded video to workspace\\output.mp4\n",
      "\n",
      "==================================================\n",
      "Pipeline complete!\n",
      "Output: workspace\\output.mp4\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import gc_seg.post_processor\n",
    "importlib.reload(gc_seg.post_processor)\n",
    "\n",
    "\n",
    "\n",
    "# Phase 6: Post-process and encode\n",
    "print(\"=\" * 50)\n",
    "print(\"PHASE 6: Post-Process & Encode\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Bypass bilateral: {BYPASS_BILATERAL}\")\n",
    "\n",
    "output_video = process_video(\n",
    "    merged_frames_folder=str(MERGED_FRAMES_FOLDER),\n",
    "    original_video=VIDEO_PATH,\n",
    "    output_path=str(OUTPUT_PATH),\n",
    "    bilateral_d=9,\n",
    "    bilateral_sigma_color=0.1,\n",
    "    bilateral_sigma_space=0.1,\n",
    "    encoder=ENCODER,\n",
    "    encoder_preset=ENCODER_PRESET,\n",
    "    encoder_crf=18,\n",
    "    bitdepth=10,\n",
    "    bypass_bilateral=BYPASS_BILATERAL,\n",
    "    upscale_resolution=UPSCALE_RES,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"Pipeline complete!\")\n",
    "print(f\"Output: {output_video}\")\n",
    "print(f\"{'=' * 50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The GC-SEG pipeline has completed all 6 phases:\n",
    "\n",
    "1. **Metadata & Mapping**: Created segment mapping\n",
    "2. **AI Inference**: Generated point maps for each segment\n",
    "3. **Extraction**: Converted to 16-bit disparity PNGs\n",
    "4. **Alignment**: Computed scale/shift coefficients\n",
    "5. **Merge & Blend**: Created seamless frame sequence\n",
    "6. **Post-Process**: Applied bilateral filter and encoded to video\n",
    "\n",
    "Output video saved to: `workspace/output.mp4`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometrycrafter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
